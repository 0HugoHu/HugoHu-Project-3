[![Install](https://github.com/nogibjj/HugoHu-Project-2/actions/workflows/lint.yml/badge.svg)](https://github.com/nogibjj/HugoHu-Project-2/actions/workflows/lint.yml)
[![Lint](https://github.com/nogibjj/HugoHu-Project-2/actions/workflows/rustfmt.yml/badge.svg)](https://github.com/nogibjj/HugoHu-Project-2/actions/workflows/rustfmt.yml)
[![Format](https://github.com/nogibjj/HugoHu-Project-2/actions/workflows/binary.yml/badge.svg)](https://github.com/nogibjj/HugoHu-Project-2/actions/workflows/binary.yml)
[![Test](https://github.com/nogibjj/HugoHu-Project-2/actions/workflows/tests.yml/badge.svg)](https://github.com/nogibjj/HugoHu-Project-2/actions/workflows/tests.yml)


[Youtube Video Here](https://youtu.be/tKc4hfgMkNs) 
&nbsp;&nbsp;![YouTube Video Views](https://img.shields.io/youtube/views/tKc4hfgMkNs)


## Individual Project #3: Databricks ETL (Extract Transform Load) Pipeline

### Description
This project uses the [Customer Shopping Trends Dataset](https://www.kaggle.com/datasets/iamsouravbanerjee/customer-shopping-trends-dataset/data) provided by Kaggle to analyze ```age``` and ```subscription``` factors vs. ```sales number``` and ```categories```. 
The dataset is stored in a CSV file and is loaded into a Databricks Delta Lake table. The data is then transformed using Spark SQL and the results are visualized using Databricks. 
The Databricks ETL Pipeline is setup by reusing the extract, transform, and query and visualization code.


### How to run


### Usage of Delta Lake


### Usage of Spark SQL


### Visualization and Conclusion


### Databricks ETL Pipeline


### Conclusion

